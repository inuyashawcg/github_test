////////////// leveldb //////////////
https://leveldb-handbook.readthedocs.io/zh/latest/basic.html
https://github.com/google/leveldb

https://www.zhihu.com/question/19887265
https://cloud.tencent.com/developer/article/1441835
https://zhuanlan.zhihu.com/p/181498475

http://blog.mrcroxx.com/categories/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAleveldb/


leveldb 是一个写性能比较优秀的存储引擎，基于典型的 LSM 树(Log Structured-Merge Tree)实现。该树的核心思想是
放弃部分读性能，换取最大的写入能力。实现原理就是尽可能减少随机写的次数。对于每次写入操作，并不是直接将最新的数据驻留
在磁盘中，而是将其拆分成：
  1、一次日志文件的顺序写
  2、一次内存中的数据插入
只有当内存中的数据达到一定的阈值，才会将这部分数据回写到磁盘当中，因此获得了极高的写性能(顺序写 60MB/s，随机写 45MB/s)

LevelDB 基本组成构件：
  1、memtable
      - leveldb 的一次写入操作并不会直接将数据刷新到磁盘文件，而是首先写入到内存， memtable 就是一个在内存中进行
        数据组织与维护的结构
      - memtable 中的所有数据都可依据用户自定义的排序方法按序存储，等到数据量达到阈值(默认4MB)，便会将其转换成一个
        不可被修改的 memtable。与此同时，会创建一个新的 memtable，提供给用户继续进行读写
      - memtable 底层使用了一种跳表数据结构，其效率可比拟二叉查找树，绝大多数操作的时间复杂度为 O(log n)

  2、immutable memtable
      - 不可被修改的 memtable，与 memtable 的结构定义完全一致，只不过它是只读的
      - 当一个 immutable memtable 被创建时，leveldb 的后台压缩进程便会将其制作成一个 sstable 对象，
        并持久化到磁盘文件中

  3、log(journal)
      - 假设写入到内存中的数据还没来得及持久化，leveldb 进程发生了异常，亦或是主机发生了宕机，则会造成用户
        写入的数据发生丢失
      - leveldb 在写内存之前，会首先将数据写入到日志文件，避免上述情况发生
      - 每次日志写操作都是一次顺序写，因此写效率高，整体写入性能较好
      - leveldb 的用户写操作的原子性，同样是通过日志来实现的

  4、sstable
      - 除了某些元数据文件， leveldb 的数据主要是通过 sstable 来进行存储
      - 虽然内存中的所有数据都是按序排列，但是当多个 memtable 数据持久化到磁盘后，不同的 sstable 之间是存在交集的。
        在读操作时，需要对所有的 sstable 文件进行遍历，严重影响读取效率
      - leveldb 后台会"定期"整合这些 sstable 我呢间，该过程也被称作 compaction。随着 compaction 的进行，sstable
        文件在逻辑上被分成若干层级，由内存数据直接 dump 出来的文件成为 level 0 层文件，后期整合而成的文件成为 level i
        层文件，这也是 leveldb 名称的由来
      - sstable 中的数据是不可被修改的

  5、manifest
      - leveldb 中包含"版本"概念，一个版本中记录了每一层中所有文件的元数据，包括:
          #文件大小
          #max key
          #min key
      - 版本信息十分重要，除了在查找数据时，利用维护的每个文件 max/min key 来加快查找，还在其中维护了一些进行 compaction 的
        统计值，来控制 compaction 的进行

  6、current
      - 该文件的内容只有一个信息，就是记录当前的 manifest 文件名
      - 每次 leveldb 启动时，都会创建一个新的 manifest 文件。因此数据目录中可能会存在多个 manifest 文件
      - current 则是用来执行哪个 manifest 文件才是我们需要关心的


LevelDB 写操作：
- leveldb 对外提供的写入接口包括：
    1、put
    2、delete
  这两种本质对应同一种操作，delete 操作同样会被转换成一个 value 为空的 put 操作；除此之外，leveldb 还提供了一个 batch 工具，
  用来批量处理数据库更新操作，并且这些操作都是原子性的

- 无论是 put / delete，或者是批量操作，底层都会为这些操作创建一个 batch 实例作为一个数据库操作的最小执行单元。batch 结构如下:
  
  | type | key length | key | value length | value |

  batch 中的每一条数据都是按照上述格式进行编码(说明 batch 类似一个容器，其中包含有多个数据条目)；
  "type" 表示该数据条目的操作类型 (更新/删除)。如果不是删除操作，则再加上 value length 和 value；
  batch 中会维护一个"size"值，用于表示其中包含的数据量的大小。"它是所有数据项 key 和 value 长度的累加，以及每条数据项额外的8字节。
    这 8 字节的数据用于存储一条数据项的额外信息。"

Key 值编码：
- 当数据项从 batch 写入到内存数据库中时，需要一个 key 值的转换，即在 leveldb 的内部，所有数据项的 key 的都是经过特殊编码的，
  被称为 "internalKey"。它的结构如下:

  | uKey | sequence number(7 bytes) | type (1 byte) |

  internalKey 在用户 key 的基础上，在尾部追加了 8 字节，用于存储 sequence number 和 type；
  每一个操作都会被赋予一个 sequence number，该计数器是在 leveldb 内部进行维护，每进行一步操作就做一次累加。leveldb 一次更新或者
    删除，采用的是 append 的方式，并非直接更新源数据。因此对应同样的一个 key，会有多个版本的数据记录，而最大的 sequence number 
    对应的数据记录就是最新的；
  snapshot 也是利用 sequence number 实现的，即每一个 sequence number 就代表一个数据库的版本

合并写：
- leveldb 在并发写入时，做了一个优化处理。在同一时刻，只允许一个写入操作将内容写入到日志文件以及内存数据库中。在写入进程较多的情况下，
  为了减少日志文件的小写入，增加整体的写入性能，leveldb 将"一些小写入合并成一个大写入"

  总体流程：
    - 第一个获取到写锁的写操作
      1、第一个写入操作获取到写入锁
      2、在当前写操作的数量未超过上限，且有其他写操作 pending 的情况下，将其他写操作的内容合并到自身
      3、若本次写操作的数量超过上限，或者无其他写操作 pending，将所有内容统一写入日志文件，并写入到内存数据库中
      4、通知每一个被合并的写操作的最终结果，释放或者移交写锁
    
    - 其他写操作
      1、等待获取写锁或者被合并
      2、若被合并，判断是否合并成功，若成功，则等待最终写入结果；反之，则表明获取锁的写操作已经 oversize 了。此时，该操作直接从上个
         占有锁的写操作中接过写锁进行写入
      3、若未被合并，则继续等待写锁或者等待被合并

原子性：
- leveldb 的任意一个写操作(无论包含了多少次写)，其原子性都是由日志文件实现的。一个写操作中所有的内容都会以一个日志中的一条记录，作为
  最小单位被写入

  异常情况处理：
    1、写日志未开始，或者写日志完成一半，进程异常退出；
      - 此时可能一个写操作的的部分写已经被记载到日志文件中，仍然有部分写未被记录
      - 当数据库重新启动恢复时，读到这条日志记录时，发现数据异常，则直接丢弃或退出

    2、写日志已经完成，进程异常退出
      - 此时写日志已经完成，写入日志的数据还未持久化
      - 数据库启动恢复时，通过 redo 日志实现数据写入


LevelDB 读操作：
- leveldb 给用户提供了两个接口进行数据读取：
    1、直接通过 get 接口读取数据
    2、首先创建一个 snapshot，基于该 snapshot 调用 get 接口读取数据
  两者本质上是一样的，只不过第一种调用方式默认以当前数据库的状态创建一个 snapshot，并基于此 snapshot 进行读取

  snapshot：
    - 简单来说，就是数据库在某一个时刻的状态。基于一个快照进行数据的读取，读到的内容不会因为后续数据的更改而改变
    - 快照代表着数据库某一个时刻的状态。在 leveldb 中，直接使用一个整型数代表一个数据库的状态
    - 用于对同一个 key 的若干次修改 (包括删除) 是以维护多条数据项的方式进行存储的 (直到进行 compaction 时才会
      合并成同一条记录)，每条数据项都会被赋予一个序列号，代表这条数据项的新旧状态。序列号越大，就代表其中的内容越新
    - 所以，每一个序列号其实就代表着 leveldb 的一个状态，即每一个序列号都可以作为一个状态快照
  
  读操作步骤：
    1、在 memory db 中查找指定的 key，若搜索到符合条件的数据项，则结束查找
    2、在冻结的 memory db 中查找指定的 key，若找到符合条件的数据项，则结束查找
    3、按照从低层到高层的顺序，在 level i 层的 sstable 文件中查找指定的 key，若找到符合条件的数据项，则结束查找；
       否则返回 Not Found error，表示在数据库中不存在指定的数据
    
    注意：
      - 在每一层 sstable 中查找数据时，都是按序依次查找 sstable
      - 0 层的文件比较特殊。因为0层文件中可能存在 key 重合的情况，因此会优先在文件编号比较大的 sstable 查找。理由是
        文件编号大的 sstable 中存储的总是最新的数据
      - 非 0 层文件，一层中所有文件之间的 key 不重合，因此 leveldb 可借助 sstable 的元数据(一个文件中最小和最大的
        key值) 进行快速定位，每一层只需要查找一个 sstable 文件的内容


日志
- 在 leveldb 中，有两个 memory db，以及对应的两份日志文件。其中一个 memory db 是可读可写的，当这个 db 的数据量超过
  预订的上限时，便会转换一个不可写的 memory db，与此同时，与之对应的日志文件也会变成一个 frozen log
- 新生成的 immutable memory db 则会由后台的 minor compaction 进程将其转换成一个 sstable 文件进行持久化。持久化完成
  之后，与之对应的 frozen log 被删除

  日志结构：
    - 为了增加读取效率，日志文件中按照 block 进行划分，每个 block 的大小为 32k，每个 block 中包含了若干个完整的 chunk
    - 一条日志中包含有一个或者多个 chunk
    - 每个 chunk 包含了一个7字节的 header。前4个字节是校验码，紧接着2字节是 chunk 数据的长度，最后一个字节是 chunk 类型
    - checksum 校验的范围包括 chunk 类型以及随后的 data 数据
  
  chunk 一共分成4种类型:
    - full
    - first
    - middle
    - last
  
  - 若一条日志中只包含一个 chunk，则 chunk 的类型是 full
  - 若一条日志包含多一个 chunk，则 chunk 的第一个类型是 first，最后一个类型是 last，
    中间包含0个或多个 middle 类型 chunk
  - 当一条日志文件过大时，会将第一部分数据写在第一个 block 中，且类型是 first。若剩余数据仍然超过一个 block 的大小，
    则第二部分卸载第二个 block 中，类型为 middle，剩余数据写在最后一个 block 中，类型为 last


////////////////// 硬核课堂笔记 //////////////////
slice 是 leveldb 中自定义的字符串处理类型，主要是因为标准库中的 string:
  - "默认语义为拷贝，会损失性能(在可预期的条件下，传递指针即可)"
  - "标准库不支持 remove_prefix / starts_with 等函数，使用起来不太方便"
  - 当我们遇到需要设计处理字符串的类时，一定要考虑数据拷贝带来的性能损失，还有构造函数的实现方式等


编码，包括定长编码和变长编码
  - 变长编码是为了减少空间占用。其基本思想是: 高位 bit 用 0/1 表示该整数是否结束，用剩余 7bit 表示实际的数值，在 protobuf
    中被广泛运用

  在内存频繁释放的地方，考虑到代码执行效率，一般都会给它安排一个内存池。在 leveldb memtable 组件中，会有大量内存申请和释放，
即 put 和 数据 dump 到磁盘

  引用计数是一种内存管理方式。在 leveldb 中，memtable/version 等组件，可能被多个线程共享，因此不能直接删除，需要等到没有
任何一个进程再占用的时候，才能删除。引用计数是通过一个 SharedPtr 类来实现的，这里有一个需要注意的点:
  class SharedPtr {
    public:
      ....
    
    private:
      void* data;
      uint32_t* ref_count; // 注意，这里使用的是一个 uint32_t 类型的指针，而不是对象
  }

  采用上述设计的原因是，如果是使用栈对象，拷贝构造函数相当于是一个传值，不同的 SharedPtr 对应的计数是独立的，而不是所有的
指针都操作同一个数据。所以，要使用指针变量，并且在拷贝构造函数时要使用深拷贝，而不能浅拷贝

  sequenceNumber 是一个 64 位数字，但是只用到了 7 个字节，剩下的一个字节表示数据类型 (比如该数据用于删除还是插入等等)

Key 的分类:
  - user key: 用于输入的数据 key (slice 格式)

  - internalKey: 内部 key，常用来比如 key 比较的场景。它其实是一个序列化的字符串，里面包含有不同类型的数据，所以操作起来
    会比较麻烦。leveldb 又提供了一个 ParsedInternalKey 类来辅助进行处理

  - ParsedInternalKey:
      对 InternalKey 进行解析
      slice user_key
      sequence number
      type

  - lookup key: get() 操作会使用到的 key，成员变量包括:
       char* start_
       char* kstart_
       char* end_
       char space[200]: 如果 key 数据量比较小，则直接存放到栈上。否则，需要从堆内存中动态申请

compare类型:
  在 leveldb 中，无论是插入，还是删除，key 之间的比较是不可避免的。于是乎，抽象除了一个基类 Comparator(思考其中蕴含的设计思想)

  实现上主要是包含两种情形:
    - BytewiseComparetorImpl
    - InternalKeyComparator: 其实内部实现也是调用 BytewiseComparetorImpl 中的相关方法


leveldb 是一个跨平台的数据库，所以提供了 Env 组件来封装跨平台相关内容。Env 是一个纯虚类，目前主要包含三方面的实现:
  - PosixEnv: 封装了 posix 标准下的所有接口
  - WindowsEnv: 封装了 Windows 下的相关接口
  - EnvWrapper: 虽然该类也是继承自 Env，但它是将所有的调用都转发到其他 Env 下实现，可能对希望覆盖另一个 Env 下部分功能的用户有用。
                不过默认还是使用 Env 实现类 (感觉像是使用了设计模式中的代理模式)


  leveldb 会提供一个资源限制类 Helper or Limiter 去限制资源的使用，以免资源被耗尽。目前限制主要是用于只读文件描述符和 mmap 文件
描述符的使用，这样我们就不会完全用完文件描述符和虚拟内存，或者遇到非常大的数据库内核性能问题。并且使用原子变量，保证线程安全

文件操作相关的类:
  - RandomAccessFile
  - PosixRandomAccessFile
  - PosixMmapAccessFile
  - SequencialFile: PosixSequencialFile / WindowsSequencialFile
  - FileLock

