////////////// 20220207 //////////////
  kern_lockf.c：
    struct lockf_entry->lf_inode 成员的类型是 struct inode，有些函数中存在如下实现：
      lock->lf_inode = (struct inode *)0;
    感觉每种文件系统的 inode 结构的命名应该都是 struct inode，而不能是 struct tpt_inode？

  Linux 中对于多进程对同一个文件的读写机制：
    1、linux 中既可以对文件的某个区段进行加锁，也可以对整个文件进行加锁 (BSD应该也是同样的机制，或者更严格一些)
    2、linux 系统会提供一个强制锁(mandatory lock)和劝告锁(advisory lock)
    3、不管是劝告锁还是强制锁，它们都可以使用共享读锁和独占写锁。在文件的某个区字段上，可以有任意多个进程进行读，
      但是在同一时刻只能有一个进程进行写；此外，当其他进程对同一个文件都拥有自己的读锁时，就不可能获得一个写锁，
      反之亦然
    4、linux 中还引入了另外一种基于 fcntl() 的强制锁，叫做租借锁(lease)。当一个进程试图打开由租借锁保护的文件时，
      它照样会被阻塞。然而，拥有锁的进程接受到一个信号。一旦该进程得到了通知，它应该首先更新文件，以使得文件的数据
      保持一致，然后释放锁。如果拥有者不在固定的时间间隔 (/proc/sys/fs/lease-break-time, 通常设置45秒) 内
      这么做，则租借锁就会由内核自动删除，且允许阻塞的进程继续执行


////////////// 20220223 //////////////
linux 文件锁：
  https://www.cnblogs.com/shy0322/p/9021616.html

linux flock 和 fcntl 的原理和区别：
  https://zhuanlan.zhihu.com/p/338725227
  https://zhuanlan.zhihu.com/p/427506654

  从上述博客中的描述可以看出，linux 对于同一个进程文件锁和不同进程文件锁的操作逻辑貌似是不一样的


////////////// 20220224 //////////////
  flock 和 fcntl 其实算是用户态的操作，是需要我们在用户态程序中进行文件同步访问。这个要跟内核中多进程访问同一个数据
区别开来。考虑 tptfs 和 ext2 两者的实现差别(以 vop_write 函数为例)。

  在 ext2 中的文件向磁盘进行数据同步的时候，利用的是 struct bufboj，它里边是包含有一个读写锁成员的(rw_lock)。
在我们进行数据同步的时候会首先对读写锁进行加锁，然后执行数据同步，最后解锁。所以它是可以保证多线程下的数据同步。但是 tptfs
实现则是直接用指针指到数据所在的内存地址，没有任何锁进行保护。并且还有一个点需要注意，同一个文件对应的 bufobj 应该是全局
唯一的，而基于 struct buf 设计的 tpt_buf 则是每个进程调用对应函数的时候 malloc 一个，所以不是全局唯一的，也就说明我们
在 tpt_buf 中添加锁成员是起不到任何作用的。

  锁应该添加到全局唯一的对象当中。从目前的实现来看，要么添加到 inode 当中，要么添加到 class VFile 当中。由于 inode 空间
目前越来越紧张，所以添加到 VFile 中更为合适。

  剩下的就是要考虑根据锁的使用场景判断采用那种设计，读优先或者是写优先。操作系统中还是对文件的读操作占多数，所以采用读优先可以
提高系统的整体性能。但是如果要考虑数据同步的实时性，还是写优先更好一些

  读写锁添加的位置不仅仅是在 read/write 函数那里，涉及到 struct buf 代码的地方都要重新评估和设计
  加读锁就是从从文件系统地址范围向其他地方拷贝数据，加写锁是从其他地方向文件系统地址范围拷贝数据
  inode table 应该也是读的多，写的少，所以可以使用读写锁进行同步。但是 bitmap 一般读取的时候都是要申请新的 block 或者 inode，
一般都会伴随有写操作，甚至有时候释放数据块或者整个文件的时候没有读，只有写。所以用 mutex 同步应该比较合适


////////////// 20220225 //////////////
  tptfs 数据同步要参考磁盘文件系统的设计思路。磁盘文件系统的磁盘数据块对应的 buf 应该是唯一的，否则操作系统无法保证多进程操作同一个
文件时数据的一致性。FreeBSD 中采用的方式是在 bufobj 中添加一个读写锁，现在需要判断这个 buf 在某种情况下返回什么样的锁类型，或者是否
是加锁的状态。tptfs 则需要根据这些再去决定调用某个函数时采用什么样的锁


////////////// 阅读笔记 //////////////
问题：编译器做了什么？
  编译过程一般可以分成6步：扫描、语法分析、语义分析、源代码优化、代码生成和目标代码优化
    1、源代码程序被输入到扫描器(Scanner)，它的任务很简单，仅仅进行词法分析。运用一种类似于有限状态机(Finite State Machine)的算法
      可以很轻松的将源代码的字符序列分割成一系列的记号(Token);
      Token 包括：关键字、标识符、字面量(数字、字符串等等)和特殊符号(加号、等号等)。在识别记号的同时，Scanner 也完成了其他的工作。
      比如将标志符放到符号表，将数字、字符串常量放到文字表等，以备后面的步骤使用

    2、接下来语法分析器 (Grammar Parser) 将对由 Scanner 产生的符号进行语法分析，从而产生语法树(Syntax Tree)。整个过程采用了上下文
      无关语法 (Context-free Grammar)的分析手段。Grammar Parser 生成的语法树就是以表达式 (Expression) 为节点的树。
    
    3、语义分析，由语义分析器 (Semantic Analyzer) 来完成。语法分析仅仅是完成了对表达式的语法层面的分析，但是它并不了解整个语句是否真正
      有意义。编译器所能分析的语义是静态语义 (Static Semantic)，所谓静态语义是指在编译期间就可以确定的语义。与之对应的是动态语义 
      (Dynamic Semantic)，它是在运行期间才能确定的语义。

    4、中间语言生成。现代编译器有着很多层次的优化，往往在源代码级别会有一个优化过程(源代码优化器，Source Code Optimizer)。
      其实在语法树上做优化是比较困难的，所以源代码优化器往往将整个语法树转换成中间代码 (Intermediate Code)，它是语法树的顺序表示，
      已经非常接近目标代码了。假设 2 + 6 这个操作，就可以在此期间被优化为计算出的结果 8。
      中间代使得编译器可以分成前端和后端。编译器前端负责产生机器无关的中间代码，编译器后端将中间代码转换成目标机器代码。这样对于一些可以跨平台
      的编译器而言，它们可以针对不同的平台使用同一个前端和针对不同机器平台的多个后端。

    5、目标代码生成与优化。源代码级优化器产生的中间代码标志着后续过程都属于编译器后端。编译器后端主要包括代码生成器 (Code Generator) 和目标
      代码优化器 (Target Code Optimizer)。代码生成器将中间代码转换成目标机器代码，这依赖于目标机器的类型。
      最后目标代码优化器对上述的目标代码进行优化，比如选择合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。